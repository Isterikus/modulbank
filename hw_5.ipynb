{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd           # for reading file\n",
    "import pandas_profiling as pp # statistical visualise\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv', index_col='Unnamed: 0', sep='\\t')\n",
    "test_df = pd.read_csv('data/test.csv', index_col='Unnamed: 0', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head(1)\n",
    "# test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows \t\t:  30500\n",
      "columns \t:  346\n"
     ]
    }
   ],
   "source": [
    "print (\"rows \\t\\t: \", train_df.shape[0])\n",
    "print (\"columns \\t: \", train_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Опишите препроцессинг данных, инжиниринг фич и валидацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбиваем выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['0'], axis=1)\n",
    "y_train = train_df['0']\n",
    "\n",
    "X_validation = test_df.drop(['0'], axis=1)\n",
    "y_validation = test_df['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : \n",
      "\t (30500, 345)\n",
      "\t (30500,)\n",
      "Test : \n",
      "\t (4166, 345)\n",
      "\t (4166,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train : \")\n",
    "print (\"\\t\", X_train.shape)\n",
    "print (\"\\t\", y_train.shape)\n",
    "print (\"Test : \")\n",
    "print (\"\\t\", X_validation.shape)\n",
    "print (\"\\t\", y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Удаляем признаки у которых уровень корреляция больше 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем признаки с корреляцией 1\n",
    "def    check_corr_data(train, test, type_corr):\n",
    "    corr_matrix = train.corr(method=type_corr).abs()\n",
    "    \n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    to_drop = []\n",
    "    for column in upper.columns:\n",
    "        if any(upper[column] > 0.99):\n",
    "            train.drop(column, axis=1, inplace=True)\n",
    "            test.drop(column, axis=1, inplace=True)\n",
    "            print (column)\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def     clean_corr_data(train, test, type_corr):\n",
    "    while check_corr_data(train, test, type_corr):\n",
    "        ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n",
      "333\n",
      "334\n"
     ]
    }
   ],
   "source": [
    "clean_corr_data(X_train, X_validation, 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : \n",
      "\t (30500, 103)\n",
      "\t (30500,)\n",
      "Test : \n",
      "\t (4166, 103)\n",
      "\t (4166,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train : \")\n",
    "print (\"\\t\", X_train.shape)\n",
    "print (\"\\t\", y_train.shape)\n",
    "print (\"Test : \")\n",
    "print (\"\\t\", X_validation.shape)\n",
    "print (\"\\t\", y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Кодируем категориальные признаки one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(train, test):\n",
    "#     test_length = test.shape()[0]\n",
    "    for i in train:\n",
    "        if len(train[i].unique()) < 15 and len(train[i].unique()) > 1:\n",
    "            train2 = pd.concat([train, pd.get_dummies(train[i], prefix=i)], axis=1)\n",
    "            train.drop([i], axis=1, inplace=True)\n",
    "            train = train2\n",
    "            \n",
    "            test2 = pd.concat([test, pd.get_dummies(test[i], prefix=i)], axis=1)\n",
    "            test.drop([i], axis=1, inplace=True)\n",
    "            test = test2\n",
    "#     test = test[:test_length]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation = one_hot_encoding(X_train, X_validation);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : \n",
      "\t (30500, 221)\n",
      "\t (30500,)\n",
      "Test : \n",
      "\t (4166, 217)\n",
      "\t (4166,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train : \")\n",
    "print (\"\\t\", X_train.shape)\n",
    "print (\"\\t\", y_train.shape)\n",
    "print (\"Test : \")\n",
    "print (\"\\t\", X_validation.shape)\n",
    "print (\"\\t\", y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Опять чистим коррелирующие данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120_0.0\n",
      "127_0.0\n",
      "212_1.0\n",
      "312_0.0\n",
      "312_0.39424\n",
      "312_0.4324508\n",
      "312_0.47097\n",
      "312_0.5197096\n",
      "312_0.5722851\n",
      "312_0.588824\n",
      "312_0.6608119\n",
      "312_0.7575137\n",
      "312_0.8421118000000001\n",
      "312_0.9310675\n",
      "312_1.0\n",
      "313_0.0\n",
      "313_0.016691400000000002\n",
      "313_0.052069500000000005\n",
      "313_0.0654514\n",
      "313_0.1504556\n",
      "313_0.2396119\n",
      "313_0.277947\n",
      "313_0.3472929\n",
      "313_0.461724\n",
      "313_0.6188458\n",
      "313_1.0\n",
      "314_0.0\n",
      "314_0.1178385\n",
      "314_0.1699219\n",
      "314_0.202474\n",
      "314_0.2057292\n",
      "314_0.4466146\n",
      "314_0.4889323\n",
      "314_0.5833333\n",
      "314_0.6126302\n",
      "314_1.0\n",
      "315_0.015435399999999997\n",
      "315_0.033313800000000005\n",
      "315_0.07876389999999997\n",
      "315_0.3415823\n",
      "315_0.4127147\n",
      "315_0.4488797000000001\n",
      "315_0.5901081\n",
      "315_0.6529206\n",
      "315_0.8525990999999999\n",
      "315_0.9929259\n",
      "315_1.0\n"
     ]
    }
   ],
   "source": [
    "clean_corr_data(X_train, X_validation, 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : \n",
      "\t (30500, 174)\n",
      "\t (30500,)\n",
      "Test : \n",
      "\t (4166, 170)\n",
      "\t (4166,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train : \")\n",
    "print (\"\\t\", X_train.shape)\n",
    "print (\"\\t\", y_train.shape)\n",
    "print (\"Test : \")\n",
    "print (\"\\t\", X_validation.shape)\n",
    "print (\"\\t\", y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(list(set(X_train.columns) ^ set(X_validation.columns)), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : \n",
      "\t (30500, 170)\n",
      "\t (30500,)\n",
      "Test : \n",
      "\t (4166, 170)\n",
      "\t (4166,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train : \")\n",
    "print (\"\\t\", X_train.shape)\n",
    "print (\"\\t\", y_train.shape)\n",
    "print (\"Test : \")\n",
    "print (\"\\t\", X_validation.shape)\n",
    "print (\"\\t\", y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.ProfileReport(X_test)\n",
    "# pp.ProfileReport(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### разбиваем на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_1, X_test, y_train_1, y_test = train_test_split(X_train, \n",
    "                                                   y_train,\n",
    "                                                   test_size=0.10, \n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Постройте логистическую регрессию. Укажите значение на валидации и публичном лидерборде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : \n",
      "\t (27450, 170)\n",
      "\t (27450,)\n",
      "Test : \n",
      "\t (3050, 170)\n",
      "\t (3050,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train : \")\n",
    "print (\"\\t\", X_train_1.shape)\n",
    "print (\"\\t\", y_train_1.shape)\n",
    "print (\"Test : \")\n",
    "print (\"\\t\", X_test.shape)\n",
    "print (\"\\t\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "\n",
    "params = {\n",
    "    'C' : [.01, .1, .5, 1, 1.5, 2],\n",
    "    'class_weight' : [None, 'balanced'],\n",
    "#     'intercept_scaling' : [np.arange(0, 20, 1)],\n",
    "    'penalty' : ['l2', 'l1'],\n",
    "    'tol' : [0.0001, 0.001, 0.002, 0.004]\n",
    "}\n",
    "\n",
    "best_params = {\n",
    "    'C': [0.5], \n",
    "    'class_weight': ['balanced'],\n",
    "    'penalty': ['l1'], \n",
    "    'tol': [0.0001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-910daf71300e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "log_reg = GridSearchCV(log, best_params, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "log_reg.fit(X_train_1, y_train_1)\n",
    "\n",
    "print (log_reg.best_params_)\n",
    "print (log_reg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6343168650729838"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4270, 170), (4166, 170))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame(log_reg.predict(X_validation))\n",
    "solution.to_csv('solution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Rank site  : 0.62911393    \n",
    "    Rank local : 0.63725348"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Постройте бэггинг на логистических регрессиях. Укажите значение на валидации и публичном лидерборде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Постройте случайный лес. Укажите значение на валидации и публичном лидерборде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth_values = list(range(8, 24)) + [None]\n",
    "# max_features_values = range(4, 8) + [None]\n",
    "max_depth_values = [None]\n",
    "max_features_values = [None]\n",
    "forest_params = {'max_depth': max_depth_values,\n",
    "                 'max_features': max_features_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=17)\n",
    "gsv = GridSearchCV(forest, forest_params, cv=5, n_jobs = -1, verbose=1, scoring='roc_auc')\n",
    "gsv.fit(X_train_1, y_train_1)\n",
    "print (gsv.best_params_)\n",
    "# print (gsv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gsv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5594702119269996"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3050, 170), (4166, 170))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame(gsv.predict(X_validation))\n",
    "solution.to_csv('solution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Rank site  : 0.54844339\n",
    "    Rank local : 0.55947021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Подберите лучший вариант простого ансамбля. Опишите его и укажите значение на валидации и публичном лидерборде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Сделайте стекинг. Опишите его и укажите значение на валидации и публичном лидерборде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Укажите ваш ник, значение на lb и валидации, опишите коротко решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
